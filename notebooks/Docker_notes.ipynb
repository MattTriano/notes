{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from urllib.request import urlretrieve\n",
    "from IPython.core.display import display, HTML\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.options.display.max_columns = None\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Very Good Walkthrough\n",
    "* Part 1: [The conceptual landscape of Docker](https://towardsdatascience.com/learn-enough-docker-to-be-useful-b7ba70caeb)\n",
    "* Part 2: [Useful Docker Terms](https://towardsdatascience.com/learn-enough-docker-to-be-useful-1c40ea269fa8)\n",
    "* Part 3: [Dockerfile Writing](https://towardsdatascience.com/learn-enough-docker-to-be-useful-b0b44222eef5)\n",
    "* Part 4: [Slim down Docker images](https://towardsdatascience.com/slimming-down-your-docker-images-275f0ca9337e)\n",
    "* Part 5: [Vital Docker Commands](https://towardsdatascience.com/15-docker-commands-you-should-know-970ea5203421)\n",
    "* Part 6: [Docker Volumes](https://towardsdatascience.com/pump-up-the-volumes-data-in-docker-a21950a8cd8)\n",
    "* Part 7: [Docker Security](https://towardsdatascience.com/top-20-docker-security-tips-81c41dd06f57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```docker\n",
    "How to make docker secret compatible with this docker-compose?\n",
    "\n",
    "hi,\n",
    "\n",
    "I am trying to use docker secret with a fusionauth image. But it seem like the \"/run/secrets\" part is parsed as a string. I tried to add _FILE in the back of password, but it did not work.\n",
    "\n",
    "Does anyone know how I can make this compose file docker-secret compatible?\n",
    "\n",
    "version: '3.3'\n",
    "\n",
    "services:\n",
    "  fusionauth:\n",
    "    image: fusionauth/fusionauth-app:latest\n",
    "    secrets:\n",
    "      - source: test_pw\n",
    "        target: postgres_password\n",
    "    environment:\n",
    "      POSTGRES_PASSWORD: /run/secrets/postgres_password\n",
    "      DATABASE_URL: jdbc:postgresql://db:5432/fusionauth\n",
    "      SEARCH_TYPE: database\n",
    "      FUSIONAUTH_APP_URL: http://fusionauth:9011\n",
    "    networks:\n",
    "     - db\n",
    "    restart: unless-stopped\n",
    "    ports:\n",
    "      - 9011:9011\n",
    "    volumes:\n",
    "      - fa_config:/usr/local/fusionauth/config\n",
    "\n",
    "networks:\n",
    "  db:\n",
    "    driver: bridge\n",
    "\n",
    "volumes:\n",
    "  db_data:\n",
    "  fa_config:\n",
    "\n",
    "secrets:\n",
    "  test_pw:\n",
    "    external: true\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "The challenge is that the image and software in it has to support reading the password from a file. Some images don't do that out of the box, and only support reading from an environment variable. To make it work, you might have to build a new image with an updated endpoint/run command or something. I am not really sure what you need to do for fusionauth.\n",
    "\n",
    "Looking at the Dockerfile, it seems like you could add an endpoint that would read the secret and set environment variable, then exec the run command.\n",
    "\n",
    "    https://github.com/FusionAuth/fusionauth-containers/tree/master/docker/fusionauth/fusionauth-app\n",
    "    https://fusionauth.io/docs/v1/tech/reference/configuration/\n",
    "        See the Lookup process section.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two things going on here. Your question is about how to user docker-compose with secrets and the docker-compose file that you have in your OP is mainly correct. So all is good there. That's how you use secrets with docker-compose.\n",
    "\n",
    "The problem you're having is that you can't get your secrets into your fusionauth container. The documentation on docker hub for fusionauth/fusionauth-app is scarce and doesn't say much about the environment variables.\n",
    "\n",
    "Secrets in docker aren't really magical. It's just a convenience that image maintainers give to users of their image to use the docker secrets feature. For example, take a look at the PostgreSQL image on docker hub, their documentation says, \"Currently, [secrets are] only supported for POSTGRES_INITDB_ARGS, POSTGRES_PASSWORD, POSTGRES_USER, and POSTGRES_DB.\".\n",
    "\n",
    "How the Postgres gets the secrets into the environment variables is through the startup script. If you take a look at the PostgreSQL start up script that's ran when you start a Postgres container, the start up script is just looking for environment variables named <env_var>_FILE, reading the contents of that file, and setting the environment using the contents of the file.\n",
    "\n",
    "So for an environment variable like POSTGRES_PASSWORD, the script looks for any environment variables named POSTGRES_PASSWORD_FILE, and if it exists, it will read the file and set POSTGRES_PASSWORD to the contents of that file.\n",
    "\n",
    "So in order to get this to work in your situation, you need to be familiar with the fusionauth image. If there's an entrypoint script in that container, then you can modify the entrypoint script to read the POSTGRES_PASSWORD_FILE environment variable, and set POSTGRES_PASSWORD there.\n",
    "\n",
    "The code for reading <env_var>_FILE will look something like this (I took this straight from the Postgres docker-entrypoint script):\n",
    "\n",
    "```bash\n",
    "file_env() {\n",
    "    local var=\"$1\"\n",
    "    local fileVar=\"${var}_FILE\"\n",
    "    local def=\"${2:-}\"\n",
    "    if [ \"${!var:-}\" ] && [ \"${!fileVar:-}\" ]; then\n",
    "            echo >&2 \"error: both $var and $fileVar are set (but are exclusive)\"\n",
    "            exit 1\n",
    "    fi\n",
    "    local val=\"$def\"\n",
    "    if [ \"${!var:-}\" ]; then\n",
    "            val=\"${!var}\"\n",
    "    elif [ \"${!fileVar:-}\" ]; then\n",
    "            val=\"$(< \"${!fileVar}\")\"\n",
    "    fi\n",
    "    export \"$var\"=\"$val\"\n",
    "    unset \"$fileVar\"\n",
    "}\n",
    "\n",
    "# Call the function on to do a replacement for POSTGRES_PASSWORD\n",
    "file_env 'POSTGRES_PASSWORD'\n",
    "```\n",
    "\n",
    "If there is no entrypoint script that you can overwrite, then you can build your own Dockerfile using fusionauth as a base image and then set your own Entrypoint to be a script that does this. Best of luck.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (geo_env)",
   "language": "python",
   "name": "geo_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
